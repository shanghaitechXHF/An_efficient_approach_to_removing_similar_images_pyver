# An Efficient Approach to Removing Similar Images (Python Version)

图像去重. 删除重复或相似的图像.
计算图片相似度的应用很广泛, 如google, baidu, 360等搜索引擎以图搜图的功能就是其典型应用.

# Some References:
1. 感知哈希算法(Perceptual hash algorithm).
phash算法可以使用Python调用Opencv库实现, 但是运行效率会比较慢. 可以这样处理: 在http://phash.org/官网上安装C版本的phash计算方法, 然后使用Python调用即可. phash只支持在Linux下运行.
Github上有一个imagehash库, 可以支持average hashing (aHash), perception hashing (pHash), difference hashing (dHash), wavelet hashing (wHash).
pip install ImageHash

2. 如果图像发生了旋转, 或者是基于内容的判断相似度, 那么再使用Hash算法判断图像的相似度就不合适了. 可以采用提取图像特征的方法, 如SIFT特征.
首先对图像提取SIFT/SURF特征, 然后使用最近邻的快速匹配算法. 即SIFT/SURF+FLANN.
使用SIFT或SURF特征时, 在detectAndCompute()阶段, 时间会较长, 因此也可以使用ORB特征. ORB+BF.
3. 使用训练好的ImageNet模型提取图像特征, 然后再计算图像的相似度.
结论:
1) 如果使用Hash算法, 那么基于内容的图像去重的准确率和召回率是很低的. 就算fingerprints长度再大, 也是如此. Hash算法可用于对于同一幅图像做了缩放, 水印, 调整色度的图像的相似度.
2) 采用提取SIFT/SURF/ORB特征, 然后在做特征点匹配的方法, 对于同一幅图像做了缩放, 水印, 旋转, 裁剪等常规操作后, 是可以判断相似度的.

4. 目前基于内容的图像去重任务已经明确.
即在网上抓取的衣服的图像可能是是有重复的, 这里的重复是指: 图像可能经历了旋转, 裁剪, 水印, 字幕等等比较初级的变换. 在这样的重复基础上进行图像去重, 那么上述两种方法是可以使用这种类型的去重任务的.

1) 数据集可以借助于DeepFashion数据集制作一些, 常见变换的衣物图像.
这些变换可参考https://www.infoq.cn/article/image-similarity-algorithm-on-mobile-client. 具体代码可见.

2) 计算相似度时间比较.
使用SURF特征匹配时间统计:
对于301 x 128(H x W)的图像, 耗时为0.039s, 39ms, 毫秒级.

使用ORB特征匹配时间统计:
对于301 x 128(H x W)的图像, 耗时为0.015, 15ms, 毫秒级.

使用SIFT特征匹配时间统计:
对于301 x 128(H x W)的图像, 耗时为0.31, 310ms, 毫秒级.
SURF特征匹配方法比ORB特征匹配方法效果要好很多, 比SIFT特征匹配方法省时很多!

使用phash时间统计:
对于301 x 128(H x W)的图像, 耗时为0.034s, 34ms, 毫秒级.

综上, 在进行基于内容的图像去重时, 采用基于SURF特征匹配的方法!

====================================================

采用感知哈希算法基于python-PIL的图像去重
https://blog.csdn.net/Gentle_Guan/article/details/73384767

用Python实现通过哈希算法检测图片重复的教程
http://www.jb51.net/article/63320.htm

最优去重算法探索
https://blog.csdn.net/zero1036/article/details/70153690

海量数据去重之SimHash算法简介和应用
https://blog.csdn.net/u010454030/article/details/49102565

======================================================

https://gitee.com/nanbowang/DupImageDetection

海量图片去重的方法-调研以及实现细节
摘要：本文主要调研了一下海量图片(>1000000张)去重的方法，在调研之前，先考虑一下自己能想到的方法的可行性。

能想到的方法
在调研之前，思考一下能想到的比较简单的方法。当然下面的方法都是在拿到图片特征之后做的。

方法1-按照pair计算图片的相似性
这种方法原始，简单，粗暴。基本思想就是挑选一个图片pair，按照某种方法计算相似度（可以是图片特征之间的相似度，可以是由网络计算的相似度），相似度低于某个阈值，则认为它们是重复的，然后从数据库中移除其中一张图片即可。这种方法虽然简单，但实际上并不可行，因为数据量太大，时间复杂度为O(n^2)。

方法2-感知Hash
生成图片的pHash，并计算pair之间pHash的Hamming distance。当然这种方法复杂度也是非常高的O(n^2)。

方法3-聚类
生成图片的特征向量并聚类，簇的数量需要设定的非常多(>10000)。每一个簇内计算图片对的距离，然后移除掉距离足够小的图片之一。但是这种方法复杂度也是挺高的，改进策略是进行多阶段聚类。首先设定第一次聚类的簇数为一个比较小的数(<100)，然后聚类。然后对每一个簇再分别聚类，对第i个簇c_i，设定子簇数为|c_i| / b。

网上搜到的方法
方法1-pHash分块局部探测
该算法的主要步骤是这样

生成所有图片的pHash（64bit）指纹特征，也可以是图片的二值化特征向量；
将每个图片的二值化特征等分成n等分，比如对于64bit指纹特征，n取4，那么每个等分的长度为16；
建立n个dict，其中第i个dict的key为第i个等分，值为一个list，用于存储具有相同第i个等分的的所有图片(url)；
遍历所有的dict，对每一个值（list）计算两两图片之间的Hamming distance，若有dist小于某个阈值的，则标记两者为相同的。为了测试效果，返回一部分相同的图片并显示。
这种方法需要做一些test查看每个list的规模，如果规模足够小，那么遍历一个pair的图片复杂度也不高，甚至于对于一些没有重复的图片，一个list只有单独的一张图片。不过条件是pHash的效果要比较好才行。即相似的图片pHash之间具有较小的Hamming distance。

目前的代码实现了该算法

参考：https://www.jianshu.com/p/c87f6f69d51f

方法2-若干Bucket存储可能相似的图片
这种方法也是减小可能相似的pair的搜索空间。原始的方法思想：

生成所有图片的特征向量。
选择任意一张图片x，遍历所有图片，如果存在图片a,b，使得d(a, x) =d(b, x)，那么图片a, b可能是重复的(这一步可以在O(n)内找出所有距离一样的图片对)，并进一步计算a, b之间的距离。
如果a, b的距离为0，那么说明图片a, b是重复的。
原始的方法有些不合理的条件，对距离的要求太过苛刻。一种改进是：

生成所有图片的特征向量
建立相似图片的局部搜索空间：选择一个边界样本x, 计算x到所有图片的距离，按照某种方法生成若干（>1000）的bucket，每一个bucket会存储距离处于一定范围的样本，且任意两个个bucket掌握的范围之间是不相交的。
对每一个bucket，计算图片之间的距离，并移除掉距离足够近的样本对中的一个。
关键问题是：bucket与bucket之间尽管不相交，但bucket掌握的范围边界可能仍然存在相似甚至相同的样本对。这部分样本是无法探测到的。

Bucket如何建立？比较简单的方法是计算x到其他样本的最大距离，按照最大距离将距离区间划分成若干等分。

参考：https://www.xzbu.com/8/view-7438065.htm

方法3-基于minHash的局部敏感Hash
局部敏感Hash算法希望原始特征空间中保持相邻的数据在经过某种Hash方法后依然有较高概率能保持相邻。

这里我们以基于minHash的局部敏感Hash算法为例。

首先讲解一下minHash算法的步骤：

对每个样本生成二值化的特征向量（列形式）。
所有样本的二值化特征向量按列拼成一个矩阵X_d*n，d为特征向量的维度，n为样本个数。
i = 1; 特征矩阵按行进行一个随机排列，记录每一列（每一个样本）第一次出现1的行号h_i(x)，h_1(x)可以认为是样本x的特征向量的一个近似。
重复k次步骤3，每次重复i++，并记录每一个样本的minHash向量[h_1(x), ..., h_k(x)]。该向量被称为样本x的minHash signature。
对于signature，我们可以知道有这样一个性质，越是相似的样本，相同的h_i值就越多，因为h_i是整数。

基于minHash的LSH方法步骤：

用pHash或者网络生成图片的2值化特征向量。
生成所有样本的签名（列向量），所有样本的签名按照列拼成签名矩阵X_k*n
将签名矩阵的k行等分成b个band，每一个band有r行，也就是k = r*b。
针对每一个band，分别建立一个Hash表，然后就可以把所有样本在一个band上的minHash子向量进行散列，这样相似的样本在同一个band上就非常有可能被映射到Hash表中同一个位置。

图片去重的过程就是在每一个Hash表中的每一个位置做图片对的相似度计算，然后去除掉相似度较小的图片。

这个方法主要参考了https://blog.csdn.net/yc461515457/article/details/48845775，https://xdrush.github.io/2017/08/09/%E5%B1%80%E9%83%A8%E6%95%8F%E6%84%9F%E5%93%88%E5%B8%8C/

pHash分块局部探测算法用法
重复图片查询

========================

Dhash: https://www.jb51.net/article/63320.htm

=======================

图像相似度算法:
图片是采用phash算法,一共分为四步吧.
1.将图片缩放到16*16大小,这是我们选择的合适的大小,假如宽高不一样,直接将其压到16*16,去掉细节,只保留宏观;
2.图片一共是16*16的,共256个像素,我们将图片进行灰度化,灰度化就是只有黑白灰三种,从白到黑,一共分了255层;
3.灰度化之后将图片进行DCT转换(离散余弦变化),因为为了识别有的图片旋转,这个DCT转换是将图片进行了一种压缩算法;
4.我们对这个算法进行了优化,因为之前是计算像素的均值,我们为了更准确,我们取RGB,rgb一共分为255个像素,我们将255个像素分为16段,如果像素大于0-16记为0,17到32记为1,直到255,这样就得到255位的二进制,这就是这张图片的指纹码.

得到唯一标识的指纹码之后怎么去计算像素度呢?

通过汉明距离比较两个二进制距离,如果距离小于<10的话,我们就判定两张图片相似.如果两个指纹码(二进制)一模一样,我们就判定两个是一张图片,或者类似;

视频相似度算法:
视频的话我们是通过ffmpeg(ff am pig),它是一个专门处理视频的框架,可以从视频中按针提取图片.然后就按照图片的相似度取对比了...

============================

深度学习图像检索: https://tieba.baidu.com/p/5985988362?red_tag=2277114582

==========================

图像去重，4 行代码就能实现，你值得拥有imagededup

现实中我们经常需要用到图像去重，比如为了扩充人脸图像，可以在百度、Google通过关键词下载大量人脸图像，但这些图像可能存在重复，在合并时需要去重。

这里的重复，是指图像内容完全一样，或者有少量的尺度、位移、色彩、亮度变化，或者是添加了少量其他内容等。

当然，我们可以使用类似SIFT图像匹配的方式实现，但这是很慢的。

考虑大规模图像检索去重，一般的流程是全局特征提取+特征hash+二值特征比较。

这里的全局特征提取，可以是直接在图像上进行小波变换、Gabor变换等，也可以是提取图像局部特征（如SIFT）再使用类似VLAD算法特征聚合，或者是直接提取CNN特征。

来自德国商品比较服务商Idealo开源的imagededup（图像去重的英文），是我们快速实现功能的首选。

开源地址：

https://github.com/idealo/imagededup

==========================
理解三种图像相似的Hash算法

https://blog.csdn.net/alieon/article/details/97924522

本来想自己写一篇总结图像相似hash算法，无意之中看到一篇博客真的是总结地很精妙。感觉自己远远不及，于是转载过来并添以补充代码实现。
原文链接：https://www.cnblogs.com/Kalafinaian/p/11260808.html

度量两张图片的相似度有许多算法，本文讲介绍工程领域中最常用的图片相似度算法之一——Hash算法。Hash算法准确的说有三种，分别为平均哈希算法(aHash)、感知哈希算法你(pHash)和差异哈哈希算法(dHash)。
三种Hash算法都是通过获取图片的hash值，再比较两张图片hash值的汉明距离来度量两张图片是否相似。两张图片越相似，那么两张图片的hash数的汉明距离越小。下面本文将分别介绍这三种Hash算法。

===========================

【python 图像相似度】OpenCV图像相似度ORB算法--相似图像去重

————————————————
版权声明：本文为CSDN博主「开心果汁」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/u013421629/java/article/details/87364489

无意中发现了一个巨牛的人工智能教程，忍不住分享一下给大家。教程不仅是零基础，通俗易懂，而且非常风趣幽默，像看小说一样！觉得太牛了，所以分享给大家。点这里可以跳转到教程人工智能教程

计算图片相似度的应用很广泛，如google、baidu、360等搜索引擎以图搜图的功能就是其典型应用

相似图像去重一般分为如下两个步骤
1、图像特征表达的提取
2、图像之间相似度计算两个主要步骤。

对于图像特征表达的提取，常见的手工设计特征有颜色、纹理、HOG、SIFT 和 SURF 等；此外基于深度学习的深层特征表达也经常被使用。对于图像之间相似度计算，常见的无监督距离度量方法有欧式距离、曼哈顿距离和余弦距离等；常见的有监督距离度量方法有 LMNN、KISSME、LFDA 和 MFA 等。然而这些方法基于浮点特征计算相似度，计算速度普遍较慢，因
此通过哈希学习方法将图像特征转换为二元编码，再利用汉明距离进行相似度的快速计算更加符合工业界对图像数据处理速度的要求。对于相同/相似图像，大部分全局特征（比如颜色、纹理和 HOG）不能很好地解决图像裁剪残缺和旋转变化等问题；一些局部特征（比如 SIFT 和 SURF）与基于深度学习的特征虽然表达效果较好，但是由于特征提取复杂，计算速度过于缓慢。针对以上特征提取方法存在的缺陷，我们采用一种快速特征点提取和描述算法 ORB 作为图像的特征表达，并使用汉明距离完成相似度计算。

ORB 特征具有以下优点：
1、特征提取速度快；
2、在大多数情况下，去重效果能够与 SIFT/SURF 持平；
3、提取的特征直接是二元编码形式，无需使用哈希学习方法就可以直接利用汉明距离快速计算相似度。

参考文档:https://blog.csdn.net/EDS95/article/details/70146689

————————————————
版权声明：本文为CSDN博主「开心果汁」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/u013421629/java/article/details/87364489